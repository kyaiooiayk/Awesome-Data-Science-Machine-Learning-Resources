
# NLP
***

## Scientific Articles
- [2022 | WIDE ATTENTION IS THE WAY FORWARD FOR TRANSFORMERS](https://arxiv.org/abs/2210.00640?utm_source=substack&utm_medium=email)
- [2022 | Transformer Quality in Linear Time](https://arxiv.org/pdf/2202.10447.pdf)
- [2022 | Large Language Models are Zero-Shot Reasoners](https://arxiv.org/pdf/2205.11916.pdf)
***

## Blogs
- [Rext Mining Our Dealer Reviews](https://engineering.autotrader.co.uk/2017/10/10/text-mining-dealer-reviews.html)
- [How to use Word2Vecto establish how similar two cars are](https://engineering.autotrader.co.uk/2021/02/17/interchangeable-stock.html)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Transformers from Scratch](https://e2eml.school/transformers.html#multihead)
- [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
***
